{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2\n",
    "\n",
    "## Student : Jad El Karchi - AI\n",
    "\n",
    "# Task 1 [2 pts]\n",
    "Consider a fully-connected layer with a weight matrix of shape $(N_{in}, N_{out})$.\n",
    "\n",
    "We want to reduce the number of MAC required for propagation through the layer.\n",
    "We do that by replacing weight matrix $W$ with its low-rank matrix approximation $\\hat{W}$,\n",
    "$$\\hat{W} = W_1W_2,$$\n",
    "where $W_1$ and $W_2$ have shapes $(N_{in}, R)$ and $(R, N_{out})$, respectively.\n",
    "\n",
    "a) Derive and explicit expression for $R$ that corresponds to the 4 times MAC reduction, when we replace layer $Y = W^TX$ by decomposed layer $Y=\\hat{W}^TX$. Shape of $X$ is $(N_{in}, 1)$.\n",
    "\n",
    "b) Implement both initial and decomposed layers using PyTorch and measure their MAC using FlopCO. For this task assume you have $N_{in} = 48, N_{out}=16$.\n",
    "\n",
    "*Hint: Implement fully-connected layer using nn.Linear()*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Decomposition : $Y = W^{T}.X = \\hat{W}^{T}.X = (W_{1}.W_{2})^{T}.X = W_{2}^{T}.W_{1}^{T}.X$\n",
    "\n",
    "$n_M$ : number of MAC before decomposition.\n",
    "\n",
    "$\\hat{n_M}$ : number of MAC after decomposition.\n",
    "\n",
    "Constraint to calculate R is $ n_M = \\frac{\\hat{n_M}}{4}$.\n",
    "\n",
    "$\\hat{n_M} = R.N_{in} + R.N_{out}$\n",
    "\n",
    "$n_M = N_{in}.N_{out}$\n",
    "\n",
    "Using this equation and the first constraint :\n",
    "$\\frac{R.(N_{in} + N_{out})}{4} = N_{in}.N_{out}$ \n",
    "\n",
    "So : $R = \\frac{4.N_{in}.N_{out}}{(N_{in}+N_{out})}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial FC Layer: 768\n",
      "Decomposed FC Layer: 3072\n"
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from flopco import FlopCo\n",
    "\n",
    "def calculate_R(n_in, n_out):\n",
    "    return int(4*(n_in * n_out) / (n_in + n_out))\n",
    "\n",
    "def create_initial_layer(n_in, n_out):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(n_in, n_out)\n",
    "    )\n",
    "\n",
    "def create_decomposed_layer(n_in, R, n_out):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(n_in, R),  # W_1\n",
    "        nn.Linear(R, n_out)   # W_2\n",
    "    )\n",
    "\n",
    "n_in, n_out = 48, 16\n",
    "\n",
    "# initiate variables\n",
    "R_val = calculate_R(n_in, n_out)\n",
    "initial_layer = create_initial_layer(n_in, n_out)\n",
    "decomposed_layer = create_decomposed_layer(n_in, R_val, n_out)\n",
    "\n",
    "initial_stats = FlopCo(initial_layer, img_size=(1, 1, 1, n_in))\n",
    "decomposed_stats = FlopCo(decomposed_layer, img_size=(1, 1, 1, n_in))\n",
    "\n",
    "print(\"Initial FC Layer:\", initial_stats.total_macs)\n",
    "print(\"Decomposed FC Layer:\", decomposed_stats.total_macs)\n",
    "\n",
    "# checking the constraint\n",
    "assert round(int(decomposed_stats.total_macs / initial_stats.total_macs)) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 [2 pts]\n",
    "\n",
    "Consider convolutional layer with a weight of shape $(C_{out}, C_{in}, k_{h}, k_{w})$.\n",
    "\n",
    "We want to reduce the number of MAC required for propagation through the layer. We do that by replacing weight tensor $W$ with its low-rank tensor approximation $\\hat{W}$\n",
    "\n",
    "a) $\\hat{W}$ is a rank-$R$ CP decomposition of reshaped weight tensor (we get 3-dimensional tensor of shape $(C_{out}, C_{in}, k_{h} \\times k_{w})$ by merging spatial dimensions of 4-d tensor). Find R such that MACs will be reduced 4 times after compression.\n",
    "\n",
    "- *Hint: see slides from the lecture (Layer compression via weight approximation)*\n",
    "\n",
    "b) Implement both initial and decomposed layers using PyTorch and measure their MAC using FlopCO. For this task assume you have $C_{in} = 16, C_{out}=32, k_{h} = 3, k_{w} = 3$. Both horizontal and vertical paddings are equal to 1. Stride = 1\n",
    "\n",
    "- The goal of this task is to build a compressed layer with correct shapes. So, for simplicity, you can initialize weights in decomposed layers with random weights.\n",
    "\n",
    "- If calculated R is not integer, round it down to the nearest integer value.\n",
    "\n",
    "- *Hint: Implement convolutional layer using nn.Conv2d()*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Using $n_m$ and $\\hat{n_m}$ we have :\n",
    "\n",
    "$n_m = C_{out}.C_{in}.k_{h}.k_{w}$\n",
    "\n",
    "$\\hat{n_m} = R.(C_{out} + C_{int} + k_{h}.k_{w})$\n",
    "\n",
    "Using this equation and the first constraint :\n",
    "$C_{out}.C_{in}.k_{h}.k_{w}=\\frac{R.(C_{out} + C_{int} + k_{h}.k_{w})}{4}$\n",
    "\n",
    "So : $R = \\frac{4.C_{out}.C_{in}.k_{h}.k_{w}}{(C_{out} + C_{int} + k_{h}.k_{w})}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial convolutional layer macs: 4608\n",
      "Decomposed convolutional layer macs: 331075\n",
      "71.84787326388889\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# checking the constraint\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(decomposed_stats\u001b[38;5;241m.\u001b[39mtotal_macs \u001b[38;5;241m/\u001b[39m initial_stats\u001b[38;5;241m.\u001b[39mtotal_macs)\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mround\u001b[39m(\u001b[38;5;28mint\u001b[39m(decomposed_stats\u001b[38;5;241m.\u001b[39mtotal_macs \u001b[38;5;241m/\u001b[39m initial_stats\u001b[38;5;241m.\u001b[39mtotal_macs)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ANSWER\n",
    "def calculate_R(C_in, C_out, k_h, k_w):\n",
    "    return int(4*(C_in * C_out * k_h * k_w) / (C_out + C_in + k_h * k_w))\n",
    "\n",
    "def create_initial_convolution(C_in, C_out, k_h, k_w, padding, stride):\n",
    "    return nn.Conv2d(in_channels=C_in, out_channels=C_out, kernel_size=(k_h, k_w), padding=padding, stride=stride)\n",
    "\n",
    "def create_decomposed_convolution(C_in, R, C_out, k_h, k_w, padding, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels=C_in, out_channels=R, kernel_size=(1, 1), stride=stride, padding=padding),\n",
    "        # Depth convolution\n",
    "        nn.Conv2d(in_channels=R, out_channels=R, kernel_size=(k_h, k_w), stride=stride, padding=padding, groups=R),\n",
    "        nn.Conv2d(in_channels=R, out_channels=C_out, kernel_size=(1, 1), stride=stride, padding=padding),\n",
    "    )\n",
    "\n",
    "C_in, C_out = 16, 32\n",
    "k_h, k_w = 3, 3\n",
    "padding = 1\n",
    "stride = 1\n",
    "H, W = 1, 1  # height and width\n",
    "\n",
    "# initiate variables\n",
    "R = calculate_R(C_in, C_out, k_h, k_w)\n",
    "initial_convolution = create_initial_convolution(C_in, C_out, k_h, k_w, padding, stride)\n",
    "decomposed_convolution = create_decomposed_convolution(C_in, R, C_out, k_h, k_w, padding, stride)\n",
    "\n",
    "initial_stats = FlopCo(initial_convolution, img_size=(1, C_in, H, W))\n",
    "decomposed_stats = FlopCo(decomposed_convolution, img_size=(1, C_in, H, W))\n",
    "\n",
    "print(\"Initial convolutional layer macs:\", initial_stats.total_macs)\n",
    "print(\"Decomposed convolutional layer macs:\", decomposed_stats.total_macs)\n",
    "\n",
    "# checking the constraint\n",
    "print(decomposed_stats.total_macs / initial_stats.total_macs)\n",
    "assert round(int(decomposed_stats.total_macs / initial_stats.total_macs)) == 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions\n",
    "\n",
    "## Load ResNet for Cifar100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Libraries\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim as optim\n",
    "\n",
    "import tensorly as tl\n",
    "from flopco import FlopCo\n",
    "\n",
    "from resnet_8x import ResNet18_8x\n",
    "from utils import batchnorm_callibration, get_validation_scores, fix_random_seed, get_cifar100_dataloader\n",
    "\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "tl.set_backend('pytorch')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet18_8x(num_classes=100)\n",
    "model.load_state_dict(torch.load(\"cifar100-resnet18_8x.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset_path = './'\n",
    "batch_size = 256\n",
    "num_workers = 0\n",
    "\n",
    "train_loader, val_loader = get_cifar100_dataloader(dataset_path, batch_size, num_workers, download=True)\n",
    "calibrate_batches = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model. Top 1 acc: 0.771, Top 5 acc: 0.936\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "top1_acc_orig, top5_acc_orig = get_validation_scores(model, val_loader, device=device)\n",
    "print(f'Original model. Top 1 acc: {top1_acc_orig:.3f}, Top 5 acc: {top5_acc_orig:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3 [4 pts]\n",
    "\n",
    "  a) Implement Weight-SVD decomposition of conv layer [1 pts]\n",
    "\n",
    "  b) Wrap Weight-SVD in a class as we have done in the seminar [1 pts]\n",
    "\n",
    "  c) Compress multiple conv layers by Weight-SVD, such that compression FLOPs ratio of the network will be close to 8 [1 pts]\n",
    "\n",
    "  d) Fine-tune the compressed model for 10 epochs using SGD with learning rate = 0.001 and momentum = 0.9 [1 pts]\n",
    "\n",
    "  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_layer_cr(model_stats, lnames_to_compress, cr=2):\n",
    "  '''\n",
    "  When we compres whole model with compression ratio `cr`,\n",
    "  we need to calculate layer compression ratio for each layer\n",
    "  from `lnames_to_compress`. We apply the same compression rate\n",
    "  to all layers.\n",
    "\n",
    "  Returns: float\n",
    "           layer compression ratio\n",
    "  '''\n",
    "\n",
    "  flops_to_compress = 0\n",
    "  for lname in lnames_to_compress:\n",
    "    flops_to_compress += model_stats.flops[lname][0]\n",
    "  uncompressed_flops = model_stats.total_flops - flops_to_compress\n",
    "  layer_cr = flops_to_compress * cr / (flops_to_compress +\n",
    "                                       uncompressed_flops * (1- cr))\n",
    "  return layer_cr\n",
    "\n",
    "\n",
    "def cr_to_svd_rank(layer, decomposition='spatial-svd', cr=2.):\n",
    "  '''\n",
    "  Returns layer decomposition rank given layer compression ratio `cr`.\n",
    "  Decomposition can be `spatial-svd` or `weight-svd`\n",
    "\n",
    "  Parameters:\n",
    "    layer:          nn.Module\n",
    "    decomposition:  str\n",
    "    cr:             float\n",
    "\n",
    "  Returns: int\n",
    "           layer decomposition rank\n",
    "\n",
    "  '''\n",
    "\n",
    "  weight_shape = layer.weight.shape\n",
    "  cout, cin, kh, kw = weight_shape\n",
    "\n",
    "  initial_count = cout * cin * kh * kw\n",
    "\n",
    "  if decomposition == 'spatial-svd':\n",
    "    rank = initial_count // (cr * (cin * kh + kw * cout))\n",
    "  elif decomposition == 'weight-svd':\n",
    "    rank = initial_count // (cr * (cin * kh * kw + cout))\n",
    "  else:\n",
    "    print('Wrong decomposiiton name. Should be spatial-svd or weight-svd')\n",
    "    rank = None\n",
    "\n",
    "  return int(rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Implement Weight-SVD decomposition of conv layer [3 pts]\n",
    "\n",
    "\n",
    "**Weight-SVD**\n",
    "![**Weight-SVD**](https://github.com/k-sobolev/m5-forecasting-accuracy/blob/main/Weight-SVD.PNG?raw=true)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = model.layer2[0].conv1\n",
    "weight = layer.weight\n",
    "bias = layer.bias\n",
    "\n",
    "is_bias = layer.bias is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_out, c_in, h, w = weight.shape\n",
    "c_out = layer.out_channels\n",
    "padding = layer.padding\n",
    "stride = layer.stride\n",
    "kernel_size = layer.kernel_size\n",
    "\n",
    "# reshape  conv. kernel to matrix: C_out, C_in, h, w -> C_out x C_in x w x h\n",
    "# ANSWER\n",
    "weight_reshaped = np.array(weight.view(c_out, -1).detach().cpu())\n",
    "\n",
    "# perform decomposition\n",
    "U, S, Vt = np.linalg.svd(weight_reshaped, full_matrices=False)\n",
    "\n",
    "rank = 10\n",
    "\n",
    "# perform truncation and fuse S matrix\n",
    "w0 = np.dot(np.diag(np.sqrt(S[0:rank])),Vt[0:rank, :])\n",
    "w1 = np.dot(U[:, 0:rank], np.diag(np.sqrt(S[0:rank])))\n",
    "\n",
    "\n",
    "# create conv1: 3x3 conv with C_in input channels and :rank: output channels\n",
    "# do not forget about stride and padding\n",
    "\n",
    "# ANSWER\n",
    "conv1 = nn.Conv2d(in_channels=c_in, out_channels=rank, kernel_size=kernel_size, padding=padding, stride=stride)\n",
    "# insert a weight, do not forget that conv kernel should have shape (C_in, C_out, h, w)\n",
    "conv1.weight = nn.Parameter(torch.FloatTensor(w0).view(c_in, rank, h, w))\n",
    "\n",
    "# create conv2: 1x1 conv with :rank: input channels and C_out output channels\n",
    "conv2 = nn.Conv2d(in_channels=rank, out_channels=c_out, kernel_size=(1,1), padding=padding, stride=stride)\n",
    "# insert a weight, do not forget to reshape weight\n",
    "conv2.weight = nn.Parameter(torch.FloatTensor(w1).view(rank, c_out, 1, 1))\n",
    "\n",
    "factorized_layer = nn.Sequential(conv1, conv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replaced layer : Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n"
     ]
    }
   ],
   "source": [
    "compressed_model = copy.deepcopy(model)\n",
    "print(\"replaced layer :\", compressed_model.layer2[0].conv1)\n",
    "compressed_model.layer2[0].conv1 = factorized_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(64, 10, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "  (1): Conv2d(10, 128, kernel_size=(1, 1), stride=(2, 2), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factorized_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You should have around 0.5 top-1 acc here\n",
    "\n",
    "compressed_model.to(device)\n",
    "top1_acc, top5_acc = get_validation_scores(compressed_model, val_loader, device=device)\n",
    "print(f'Compressed model. Top 1 acc: {top1_acc:.3f}, Top 5 acc: {top5_acc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Wrap Weight-SVD decomposition of conv layer in a class as we have done in the seminar [1 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD_Weight_conv_layer(torch.nn.Module):\n",
    "    def __init__(self, layer, rank=None, rank_selection='manual'):\n",
    "        super(SVD_Weight_conv_layer, self).__init__()\n",
    "\n",
    "        self.c_in = layer.in_channels\n",
    "        self.c_out = layer.out_channels\n",
    "        self.padding = layer.padding\n",
    "        self.stride = layer.stride\n",
    "        self.kernel_size = layer.kernel_size\n",
    "        self.h = layer.kernel_size[0]\n",
    "        self.w = layer.kernel_size[1]\n",
    "        self.is_bias = layer.bias is not None\n",
    "        if self.is_bias:\n",
    "            self.bias = layer.bias\n",
    "\n",
    "        if rank is None or type(rank) is not int:\n",
    "            raise AttributeError('Rank should be an integer number')\n",
    "        else:\n",
    "            self.rank = rank\n",
    "\n",
    "\n",
    "        self.svd_decomposition = self.__replace__(layer)\n",
    "\n",
    "    def __replace__(self, layer):\n",
    "        \"\"\" Gets a conv layer and a target rank,\n",
    "            returns a nn.Sequential object with\n",
    "            each layer representing a decomposed factor\"\"\"\n",
    "\n",
    "        # ANSWER\n",
    "        weight_reshaped = np.array(layer.weight.view(self.c_out, -1).detach().cpu())\n",
    "\n",
    "        U, S, Vt = np.linalg.svd(weight_reshaped, full_matrices=False)\n",
    "\n",
    "        w0 = np.dot(np.diag(np.sqrt(S[0:self.rank])),Vt[0:self.rank, :])\n",
    "        w1 = np.dot(U[:, 0:self.rank], np.diag(np.sqrt(S[0:self.rank])))\n",
    "\n",
    "        # ANSWER\n",
    "        new_layers = [\n",
    "            nn.Conv2d(self.c_in, self.rank, kernel_size=self.kernel_size, padding=self.padding, stride=self.stride),\n",
    "            nn.Conv2d(self.rank, self.c_out, kernel_size=(1,1), padding=self.padding, stride=self.stride)\n",
    "        ]\n",
    "\n",
    "        # ANSWER\n",
    "        input_kernel_size = self.kernel_size  # Input kernel size remains the same\n",
    "        output_kernel_size = (1, 1)  # Adjust based on padding\n",
    "        new_kernels = [\n",
    "            torch.FloatTensor(w0).reshape(self.c_in, self.rank, *input_kernel_size),\n",
    "            torch.FloatTensor(w1).reshape(self.c_out, self.rank, *output_kernel_size)\n",
    "        ]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in range(len(new_kernels)):\n",
    "                new_layers[i].weight = nn.Parameter(new_kernels[i].cpu())\n",
    "                if i == len(new_kernels)-1 and self.is_bias:\n",
    "                    new_layers[i].bias = nn.Parameter(self.bias)\n",
    "\n",
    "        return nn.Sequential(*new_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.svd_decomposition(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Compress many layers [1 pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)\n",
    "model_stats = FlopCo(model, img_size = (1, 3, 32, 32), device = device)\n",
    "lnames_to_compress = [lname for lname, _ in model.named_modules() if 'conv' in lname]\n",
    "lnames_to_compress = lnames_to_compress[1:]\n",
    "\n",
    "model_compression_ratio = 8\n",
    "layer_cr = calculate_layer_cr(model_stats, lnames_to_compress, cr=model_compression_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_layer_by_name, train, replace_layer_by_name\n",
    "\n",
    "compressed_model = copy.deepcopy(model)\n",
    "for lname in lnames_to_compress:\n",
    "  layer = get_layer_by_name(compressed_model, lname)\n",
    "  # ANSWER\n",
    "  # get weight-svd svd rank for given layer_cr here\n",
    "  r = cr_to_svd_rank(layer, decomposition='weight-svd', cr=layer_cr)\n",
    "  # ANSWER\n",
    "  # get compressed layer here using SVD_Weight_conv_layer\n",
    "  compressed_layer = SVD_Weight_conv_layer(layer, rank=r)\n",
    "  # replace layer by compressed layer\n",
    "  replace_layer_by_name(compressed_model, lname, compressed_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_model.to(device)\n",
    "top1_acc, top5_acc = get_validation_scores(compressed_model, val_loader, device=device)\n",
    "print(f'Compressed model. Top 1 acc: {top1_acc:.3f}, Top 5 acc: {top5_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "compressed_model_stats = FlopCo(compressed_model, img_size = (1, 3, 32, 32), device = device)\n",
    "\n",
    "print(f\"Accuracy score : {model_stats.total_flops / compressed_model_stats.total_flops}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Fine-tune the model\n",
    "\n",
    "As we can see, accuracy of our model has dropped significantly. Let's fine-tune it and see how well can we recover the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "optimizer = optim.SGD(compressed_model.parameters(), lr=0.001, momentum=0.9)  # Adjust lr and momentum as needed\n",
    "compressed_model.to(device)\n",
    "\n",
    "# ANSWER\n",
    "for epoch in range(10):\n",
    "    train(compressed_model, device, train_loader, optimizer, epoch, log_interval=100, verbose=True) # TODO: train the model\n",
    "    top1_acc, top5_acc = get_validation_scores(compressed_model, val_loader, device=device)\n",
    "    print(f'Epoch: {epoch}, top-1 acc.:{top1_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4 [2 pts]\n",
    "\n",
    "In this task you will perform whole-model compression using MUSCO package.\n",
    "\n",
    "a) Compress all 3x3 onvolutional layers:\n",
    " -  with 'cp3' with param reduction rates: 2, 4, 8\n",
    " -  with 'tucker2' with param reduction rates: 2, 4, 8\n",
    "\n",
    "b) Compare accuracy - FLOPs reduction trade off for  'cp3' and 'tucker2' - based model compressions.\n",
    "\n",
    "In this sub task, for each type of decomposition you should plot the dependancy of top-1 accuracy on FLOPs reduction rate.\n",
    "\n",
    "\n",
    "- Note: You do need to fine-tune compressed models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmusco\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CompressorVBMF, CompressorPR, CompressorManual\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_layer_by_name\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/musco/pytorch/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmusco\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CompressorVBMF, CompressorPR, CompressorManual\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/musco/pytorch/compressor/compressor.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmusco\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompress\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_compressed_model\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCompressor\u001b[39;00m():\n\u001b[1;32m     10\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    Class to perform automated compression using VBMF rank selection.\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124;03m    Layers of type nn.Conv2d 1x1 and nn.Linear are decomposed using SVD, nn.Conv2d kxk(k>1) - using Tucker2 decomposition.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/musco/pytorch/compressor/compress.py:9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabsl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmusco\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecompositions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtucker2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tucker2DecomposedLayer\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmusco\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecompositions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcp3\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CP3DecomposedLayer\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmusco\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdecompositions\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcp4\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CP4DecomposedLayer\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/musco/pytorch/compressor/decompositions/tucker2.py:5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msktensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dtensor, tucker\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmusco\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompressor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrank_selection\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mestimator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m estimate_rank_for_compression_rate, estimate_vbmf_ranks\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTucker2DecomposedLayer\u001b[39;00m():\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sktensor/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# data types\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msptensor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sptensor, unfolded_sptensor\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sktensor/core.py:269\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;124;03m    Inner prodcut with a Tensor\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdot(X\u001b[38;5;241m.\u001b[39mflatten(), Y\u001b[38;5;241m.\u001b[39mflatten())\n\u001b[0;32m--> 269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnvecs\u001b[39m(X, n, rank, do_flipsign\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m):\n\u001b[1;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;124;03m    Eigendecomposition of mode-n unfolding of a tensor\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m    273\u001b[0m     Xn \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39munfold(n)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/__init__.py:319\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    314\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    315\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    316\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[0;32m--> 319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from musco.pytorch import CompressorVBMF, CompressorPR, CompressorManual\n",
    "from utils import get_layer_by_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compressed_model(model, conv2d_nn_decomposition, model_compression_ratio=2):\n",
    "  device = 'cuda'\n",
    "  model.to(device)\n",
    "  model_stats = FlopCo(model, img_size = (1, 3, 32, 32), device = device)\n",
    "  lnames = list(model_stats.flops.keys())\n",
    "  lnames_to_compress = [lname for lname, _ in model.named_modules() if 'conv' in lname]\n",
    "  lnames_to_compress = lnames_to_compress[1:]\n",
    "\n",
    "  layer_cr = calculate_layer_cr(model_stats, lnames_to_compress, cr=model_compression_ratio)\n",
    "\n",
    "  param_reduction_rates = {lname: layer_cr for lname in lnames_to_compress}\n",
    "\n",
    "  ### Implement CompressorPR class here\n",
    "  # ANSWER\n",
    "  compressor = CompressorPR(model,\n",
    "                            model_stats,\n",
    "                            rank_selection = 'param_reduction',\n",
    "                            conv2d_nn_decomposition = conv2d_nn_decomposition,\n",
    "                            ranks = [cr_to_svd_rank(get_layer_by_name(model, lname), decomposition='weight-svd', cr=layer_cr) for lname in lnames_to_compress],\n",
    "                            param_reduction_rates = param_reduction_rates)\n",
    "\n",
    "  ###\n",
    "  compressor.lnames = lnames_to_compress\n",
    "\n",
    "  compressor.compression_step()\n",
    "\n",
    "  return compressor.compressed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of calculating model accuracy\n",
    "\n",
    "compressed_model = get_compressed_model(model, 'tucker2', 8)\n",
    "\n",
    "compressed_model.to(device)\n",
    "top1_acc, top5_acc = get_validation_scores(compressed_model, val_loader, device=device)\n",
    "print(f'Compressed model. Top 1 acc: {top1_acc:.3f}, Top 5 acc: {top5_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each model cr and each decomposition calculate:\n",
    "# FLOPs compression ratio and top-1 accuracy\n",
    "\n",
    "model_compression_ratio_list = [2, 4, 8]\n",
    "\n",
    "flops_ratio_tucker2_list = []\n",
    "top1_acc_tucker2_list = []\n",
    "\n",
    "flops_ratio_cp3_list = []\n",
    "top1_acc_cp3_list = []\n",
    "\n",
    "for ratio in model_compression_ratio_list:\n",
    "\n",
    "  compressed_model = get_compressed_model(model, 'tucker2', ratio)\n",
    "  compressed_model_stats = FlopCo(compressed_model, img_size=(1, 3, 32, 32), device=device)\n",
    "\n",
    "  flops_ratio_tucker2_list.append(compressed_model_stats.total_flops / model_stats.total_flops)\n",
    "  top1_acc_tucker2_list.append(get_validation_scores(compressed_model, val_loader, device=device)[0])\n",
    "\n",
    "  compressed_model = get_compressed_model(model, 'cp3', ratio)\n",
    "  compressed_model_stats = FlopCo(compressed_model, img_size=(1, 3, 32, 32), device=device)\n",
    "\n",
    "  flops_ratio_cp3_list.append(compressed_model_stats.total_flops / model_stats.total_flops)\n",
    "  top1_acc_cp3_list.append(get_validation_scores(compressed_model, val_loader, device=device)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and analyze results\n",
    "\n",
    "plt.plot(flops_ratio_tucker2_list, top1_acc_tucker2_list, marker='o', label='tucker2')\n",
    "plt.plot(flops_ratio_cp3_list, top1_acc_cp3_list, marker='o', label='cp3')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5: Bonus task [1 pts]\n",
    "\n",
    "In Task 2, initialize weights of decomposed layer by using factors from tensor decomposition instead of random initialization.\n",
    "\n",
    "- Hint: you can see how to perform correct factor reshapes needed for weights initialization in the seminar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANSWER\n",
    "def calculate_R(C_in, C_out, k_h, k_w):\n",
    "    return int((C_in * C_out * k_h * k_w) / (4 * (C_in + k_h * k_w + C_out)))\n",
    "\n",
    "def create_initial_convolution(C_in, C_out, k_h, k_w, padding, stride):\n",
    "    return nn.Conv2d(in_channels=C_in, out_channels=C_out, kernel_size=(k_h, k_w), padding=padding, stride=stride)\n",
    "\n",
    "def create_decomposed_convolution(C_in, R, C_out, k_h, k_w, padding, stride):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels=C_in, out_channels=R, kernel_size=(1, 1), stride=1, padding=padding),\n",
    "        # Depth convolution\n",
    "        nn.Conv2d(in_channels=R, out_channels=R, kernel_size=(k_h, k_w), stride=1, padding=padding, groups=R),\n",
    "        nn.Conv2d(in_channels=R, out_channels=C_out, kernel_size=(1, 1), stride=1, padding=padding),\n",
    "    )\n",
    "\n",
    "# ANSWER    \n",
    "def initialize_decomposed_convolution_weights(layer, w0, w1):\n",
    "    # Initialize the weights of the decomposed convolutional layer\n",
    "    with torch.no_grad():\n",
    "        layer[0].weight = nn.Parameter(torch.Tensor(w0))\n",
    "        layer[1].weight = nn.Parameter(torch.Tensor(w1))\n",
    "\n",
    "# initiate variables\n",
    "rank = calculate_R(C_in, C_out, k_h, k_w)\n",
    "initial_convolution = create_initial_convolution(C_in, C_out, k_h, k_w, padding, stride)\n",
    "decomposed_convolution = create_decomposed_convolution(C_in, R, C_out, k_h, k_w, padding, stride)\n",
    "\n",
    "# Calculate SVD and get factors w0 and w1\n",
    "weight_reshaped = np.array(initial_convolution.weight.view(C_out, -1).detach().cpu())\n",
    "\n",
    "U, S, Vt = np.linalg.svd(weight_reshaped, full_matrices=False)\n",
    "\n",
    "w0 = np.dot(np.diag(np.sqrt(S[0:rank])), Vt[0:rank, :])\n",
    "w1 = np.dot(U[:, 0:R], np.diag(np.sqrt(S[0:rank])))\n",
    "\n",
    "# Initialize the decomposed convolutional layer weights\n",
    "initialize_decomposed_convolution_weights(decomposed_convolution, w0, w1)\n",
    "\n",
    "# Calculate and print the FLOPs for both layers\n",
    "initial_stats = FlopCo(initial_convolution, img_size=(1, C_in, H, W))\n",
    "decomposed_stats = FlopCo(decomposed_convolution, img_size=(1, C_in, H, W))\n",
    "\n",
    "print(\"Initial convolutional layer macs:\", initial_stats.total_macs)\n",
    "print(\"Decomposed convolutional layer macs:\", decomposed_stats.total_macs)\n",
    "\n",
    "# Checking the constraint\n",
    "assert int(initial_stats.total_macs / decomposed_stats.total_macs) == 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
